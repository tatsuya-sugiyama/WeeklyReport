%\documentstyle[epsf,twocolumn]{jarticle}       %LaTeX2e仕様
\documentclass[twocolumn]{jarticle}     %pLaTeX2e仕様(platex.exeの場合)
% \documentclass[onecolumn]{ujarticle}   %pLaTeX2e仕様(uplatex.exeの場合)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  基本バージョン
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\topmargin}{-45pt}
%\setlength{\oddsidemargin}{0cm}
\setlength{\oddsidemargin}{-7.5mm}
%\setlength{\evensidemargin}{0cm}
\setlength{\textheight}{24.1cm}
%setlength{\textheight}{25cm}
\setlength{\textwidth}{17.4cm}
%\setlength{\textwidth}{172mm}
\setlength{\columnsep}{11mm}

%\kanjiskip=.07zw plus.5pt minus.5pt


% 【節が変わるごとに (1.1)(1.2) … (2.1)(2.2) と数式番号をつけるとき】
%\makeatletter
%\renewcommand{\theequation}{%
%\thesection.\arabic{equation}} %\@addtoreset{equation}{section}
%\makeatother

%\renewcommand{\arraystretch}{0.95} 行間の設定
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{graphicx}   %pLaTeX2e仕様(\documentstyle ->\documentclass)
\usepackage[dvipdfmx]{graphicx}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{url}
\usepackage{ulem}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{listings} %,jlisting} %日本語のコメントアウトをする場合jlistingが必要
%ここからソースコードの表示に関する設定
\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

	%bibtex用の設定
	%\bibliographystyle{ujarticle}

	\twocolumn[
		\noindent
		\hspace{1em}
		2020 年 7 月 13 日
		発表資料
		\hfill
		B4 杉山　竜弥
		\vspace{2mm}

		\hrule
		\begin{center}
			{\Large \bf 進化的な深層学習の構築に関する研究}
		\end{center}
		\hrule
		\vspace{9mm}
	]

  % 背景
  % 要素技術
  % 実験目的
  % 実験方法
  % 4p?
  % slackで連絡

  % 進化的な深層学習の構築に関する研究
  % AutoML
  % NAS
  % DataAugment
  %
  % DataAugment | NN, SVM, RF(包括的)
  %
  % DataAugment 最後の方の実験結果
  %
  % （進化的な人工知能の構築に関する研究）

\section{はじめに}
% ちょっと
% 人工知能の成功が目覚ましい
% 人の手が必要
% 専門知識が必要
% 困難である
% 深層学習の広範囲な（メタな）技術のサーベイ

機械学習の成功は目覚ましく, 広い分野に適用され多くの研究がなされている.
その中でディープニューラルネットワーク(deep neural network; DNN)は, 音声・画像・自然言語を対象とした問題で高い性能を示し, 強い関心を集めた.
層を深く重ねるDNNは, 層の種類やその数, 層同士の接続, 畳み込み層の場合はカーネルサイズやストライドなど, 多数のパラメータが存在する.
問題に合わせて適切なパラメータを選択しなければ良好な精度が出ない一方で, そのネットワークやアーキテクチャの設計に明確な指針はなく非常に困難である. 従来では, 専門知識を持つ人が手作業で設計し, 学習した結果を参照して繰り返し修正していた.


自動化された機械学習(Automated Machine Learning; AutoML)と呼ばれる分野は, アーキテクチャ全体を対象とした最適化を目指す.
本研究ではAutoMLの開発を行う前段階として, AutoMLの調査を行った. まずAutoMLの分類を見た後, その例であるNeural Architecture Search: NASとAuto Augmentについて紹介する.
% 本研究ではAutoMLの調査を行い, その分類と例をまとめる.

\section{要素技術}
\subsection{AutoML}
自動化された機械学習(Automated Machine Learning; AutoML)は特定の技術ではなく, 機械学習モデルの設計を自動化する全般的な手法, または概念を指す.

問題ごとにパラメータを適切に設定する必要があるというパラメータ設定問題の解決を目的とする.
確率的なブラックボックスメタ最適化であるこの問題の解決によって,
\begin{itemize}
  \item 時間コストの削減・性能の向上
  \item アルゴリズムの評価, 比較のためパラメータの最適性の影響を緩和
  \item パラメータが与える影響の知識の必要性を排除
\end{itemize}
の3つの利益が得られる.

AutoMLはそのアルゴリズムによって, 以下の3つの主要カテゴリと6つのサブカテゴリに分類される\cite{SurveyAutoML}.

\paragraph{主要カテゴリ}
構造や構成による分類
\begin{enumerate}
  \item 単純な生成・評価法 \\
  生成段階で候補となる設定を生成, 評価段階で評価して最適な設定を見つける手法.

  \item 反復的生成・評価法 \\
  少数の設定を生成して, 最も優れたものをみつけ, 反復的に生成する新しい設定の指針とする手法.

  \item 高レベルの生成・評価方法 \\
  高レベル生成機構として既存の自動パラメータチューニング手法や探索手法を持ち,
  少数精鋭の設定を生成し評価段階では慎重に評価する手法.
\end{enumerate}

\paragraph{サブカテゴリ}
評価方法による分類
\begin{enumerate}
  \item 繰り返し評価法 \\
  複数回の評価を, 平均することなどで評価する手法.

  \item F-Racing \\
  統計的に劣る評価の設定を段階的に排除し, 有望な候補に計算を集中する手法. 繰り返し評価より効率的になる.

  \item インテンシフィケーション(強化) \\
  % 評価途中で候補設定が暫定設定より劣るなら排除し, そうでなければ次の問題で評価する. 全ての問題で評価されると新しい暫定設定となる手法.
  問題のリストで候補設定と暫定設定の評価を次々比較し, 劣る場合は途中で排除し, そうでなければ候補が暫定設定となる手法.

  \item シャープニング \\
  少ないテスト数で評価を始め, 将来性のある設定のテスト数を2倍にすることで素早く探索できる手法.

  \item アダプティブキャッピング  \\
  有望でない設定の実行を中断して計算量を削減できる手法.
\end{enumerate}

\subsection{NAS}
% AutoMLの一種
従来の機械学習では手作業によって設計されたモデルをデータセットで学習して重みの最適化を行うが, アーキテクチャの設計には, 高度な専門知識と手作業による構築が必要である.
Neural Architecture Search(NAS)\cite{DBLP:journals/corr/ZophL16}は, ニューラルネットワークのアーキテクチャ自体を最適化する.

% 最適化のためまずアーキテクチャを, レイヤーの種類やその接続を表すハイパーパラメータで表現する.


アーキテクチャの探索は3つの段階で行う.
まず最初にコントローラと呼ばれる再帰型ニューラルネットワーク(Recurrent Neural Network; RNN)で, アーキテクチャのハイパーパラメータを生成する.
例えば畳み込み層を利用するネットワークでは, レイヤーごとにフィルタの高さ・幅, ストライドの高さ・幅, フィルタ数が必要となる.
次にハイパーパラメータから子ネットワークを構築し, 通常のように重みを訓練して検証データセットの精度を得る.
最後に得られた精度で報酬を計算し, 方策勾配法(Policy gradient method)によってコントローラのネットワークを更新する.
これらの手順を繰り返すことで, 子ネットワークのアーキテクチャが最適化される.
% 方策勾配法：Policy(=ネットワーク)の勾配と価値関数の積を報酬として更新
% 最良の子ネットワークがコントローラが見つけたアーキテクチャとなる.

NASでは子ネットワークとして, 畳み込みネットワークとRNNの探索を行い従来のネットワークより高い精度と少ないパラメータ数を達成したが, 数百台のGPUと1ヶ月の時間がかかり計算量に問題があった.
以降の研究では計算量の削減を目的とした手法が提案された.

佐藤 怜ら\cite{ANAS}の研究では, NASを改良した先行研究に比較してより高速なアルゴリズムを開発した.

\begin{itemize}
  \item アーキテクチャをカテゴリカルから連続的な確率分布に
  \item ネットワークの重みを再利用して学習を削減
  \item 見つけたアーキテクチャの重みを再学習する(acc 6割 $\rightarrow$ 9割)
\end{itemize}

\paragraph{重みの再利用}
\begin{enumerate}
  \item 冗長にネットワーク構造を決めておく. (あるノードはそれ以前のノード全てに接続可能とする)
  \item 重みを学習して、各エッジ、各演算子ごとに重みを保存
  \item アーキテクチャ（接続するか？＋演算子）を探索
\end{enumerate}

得られたセルでは,
直前のセルからの入力を恒等写像でそのまま出力していた.

畳み込み層は全てseparable convolutionを利用している. パラメータ数を減らしたかった？

\paragraph{アーキテクチャの表現法}
\begin{itemize}
  \item RNNでパラメータを生成(カテゴリカル)
  \item GAで個体表現(カテゴリカル)
  \item 演算子の確率分布集合として表現
\end{itemize}

\subsection{AutoAugment}
\cite{DBLP:journals/corr/abs-1805-09501}
AutoMLの一種？
(編集しよう！)
画像認識の分野では、画像データを少し回転させたり左右反転させたりなどの操作をすることで画像データ数を増やすData Augmentation(以下、DA)が広く使われています。ただ、どの操作を行うのかというのは試行錯誤で見つけるしかなく時間がかかります。そこで強化学習を使うことで自動的にDAを選択してくれるというAutoAugmentが提案されました。

\section{実験}
% ＋結果
% 本実験ではｘ 本研究ではo
% １ｐ
～に関する実験の前段階として, 以下の予備実験を練習的に行った.
アンサンブル学習に関連？

\subsection{モデルの構築}
cifar10\cite{cifar10}
前回, 5クラス識別器を2つ利用したモデルの構築をしたが, 10クラスの識別が50\%であったため, より適したパラメータを探索し, 再び実験して精度の向上を目指した.

\begin{table}[tb]
  \begin{center}
    \caption{実験の設定}
    \begin{tabular}{|c|c|} \hline
      dataset & cifar10 \\
      n data & 16,000 / model \\ \hline
      task & 5, 7, 10クラス識別 \\
      input & image(3x32x32) \\
      output & class(5, 7, 10) \\ \hline
      model & CNN(16層) \\
      optim & SDG (lr=0.001, moment=0.9) \\
      loss & Cross Entropy Loss \\ \hline
      batch size & 64 \\
      epoch & 100 \\ \hline
    \end{tabular}
    \label{tab:setting}
  \end{center}
\end{table}

\begin{figure*}[t]
	\begin{center}
		\includegraphics[clip,width=16cm]{model_figure.png}
		\caption{モデルの簡略図　()内はデータの次元数}
		\label{fig:model}
	\end{center}
\end{figure*}

\subsubsection{5クラスx2}

cifar10に含まれる10クラスを5クラスずつに分割した。インデックスの前半(airplane, mobile, bird, cat, deer)と後半(dog, frog, horse, ship, truck)で分けることにした。生成した部分データセットを、それぞれモデルA, Bで学習した。5クラス分類ができるモデルA, Bを持つ結合モデルA + Bを作成し、10クラス分類の精度を計測した。このモデルの学習と相互関係を図\ref{fig:model}に示した。

結合モデルA + Bは10クラスのデータセットをA, Bに入力し、得られた出力をクラスインデックス順に結合して、出力とする。結合では特別な処理を行わず、そのままのデータを連結した.

\subsubsection{7クラスx3}

\begin{table}[tb]
  \begin{center}
    \caption{モデルごとの7クラスの振り分け}
    \begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|} \hline
      model & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\ \hline\hline
      A     & o & o & o & o & o & o & o & _ & _ & _ \\ \hline
      B     & o & o & o & o & _ & _ & _ & o & o & o \\ \hline
      C     & o & _ & _ & _ & o & o & o & o & o & o \\ \hline
    \end{tabular}
    \label{tab:class7}
  \end{center}
\end{table}

さらに今回は, 細川君に指摘してもらったアイデアでも実験を行った. 7クラス分類器を3つ組み合わせて,10クラスの分類を行った. 表\ref{tab:class7}のように, 2つ以上の分類器で各クラスを推定するように, クラスを振り分けた.

\subsection{結果}

\begin{figure}[tb]
	\begin{center}
		\includegraphics[clip,width=8.5cm]{accuracy5.png}
		\caption{5クラス分類の正答率}
		\label{fig:accuracy5}
	\end{center}
\end{figure}

\begin{figure}[tb]
	\begin{center}
		\includegraphics[clip,width=8.5cm]{accuracy7.png}
		\caption{7クラス分類の正答率}
		\label{fig:accuracy7}
	\end{center}
\end{figure}

5クラス分類の精度を図\ref{fig:accuracy5}に, 7クラス分類の精度を図\ref{fig:accuracy7}に示した.

5クラス分類の場合, 80\% ～ 90\%の正答率で前回よりも10\%程向上した. 前回のデータ数2000よりもデータ数を増やしたことで精度がよくなった. 結合した結果も, 70\%(前回+20\%)となった.

7クラス分類では, 正答率が平均80\%程度で, 結合した結果10クラス分類では86.7\%となった.

\subsection{考察}
% 精度が出ない，とかだけではなく自分なりの考察を示す
データ数とバッチサイズを増やして, 精度の向上と学習の安定化ができた. 特に5クラス分類ではあるが, 正答率 9割を超えることができた. データオーギュメントはしていないので, さらに精度を上げることはできると思われる.

図\ref{fig:accuracy5}, \ref{fig:accuracy7}ともにインデックスが前半のクラスを持つモデルでは, 正答率が低い傾向が見られた. 誤差の影響ではなく, 困難なクラスの分類によって精度が下がっていると考えられる. これはクラスを単純に分割したことによる偏りに原因がある.

分割する組み合わせを自由に替える実装ができたので, 様々な組み合わせパターンで実験して, その差異を見たい.
特にモデル間の正答率の差が目立ったため, これを埋めるような組み合わせを探したい.


\section{考察}

\section{まとめと今後の課題}
論文の調査をした
AutoMLとその関連技術についてまとめた

NASについて確率的なアーキテクチャ表現したシステムを構築し
簡単な問題を解く小さなネットワークを探索する実験をしたい

% 参考文献リスト
\bibliographystyle{unsrt}
\bibliography{ref}
\end{document}
