{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5 to 10","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0vxD8/zUYp3bTlQfBsYbA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"C7MTsbZo7q0H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592374860886,"user_tz":-540,"elapsed":4784,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["import torch #基本モジュール\n","from torch.autograd import Variable #自動微分用\n","import torch.nn as nn #ネットワーク構築用\n","import torch.optim as optim #最適化関数\n","import torch.nn.functional as F #ネットワーク用の様々な関数\n","import torch.utils.data #データセット読み込み関連\n","import torchvision #画像関連\n","from torchvision import datasets, models, transforms #画像用データセット諸々\n","\n","import numpy as np\n","import argparse\n","import json\n","from logging.config import dictConfig\n","from logging import getLogger\n","import os\n","import time\n","from google.colab import files"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fl8b4uzs7yxo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592374863881,"user_tz":-540,"elapsed":940,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["class CNN(nn.Module):\n","    def __init__(self, n_class=10):\n","        super(CNN, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Dropout(0.25),\n","            \n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Dropout(0.25),\n","            \n","            nn.Conv2d(128, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 512, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, padding=1),\n","            nn.ReLU(),\n","            nn.AvgPool2d(8) #???\n","        )\n","        self.pc = nn.Sequential(\n","            nn.Linear(512, 1024),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 1024),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, n_class),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = x.view(-1, 512)\n","        x = self.pc(x)\n","        return x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gNeXy87M49K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592377743035,"user_tz":-540,"elapsed":799,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["class catCNN(nn.Module):\n","  def __init__(self, models, device, n_class=10):\n","    super(catCNN, self).__init__()\n","    self.models = models\n","    self.n_class = n_class\n","    self.device = device\n","\n","  def forward(self, x):\n","    batch_size = x.shape[0]\n","    output = torch.zeros(batch_size, self.n_class).to(self.device)\n","    count = torch.zeros(self.n_class).to(self.device)\n","    for idx, model in self.models:\n","      idx = torch.tensor(idx).to(self.device)\n","      output.index_add_(1, idx, model(x))\n","      count[idx] += 1\n","    \n","    output = output / count\n","    # output = nn.Softmax(dim=1)(output)\n","    return output"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkUWcG0A70Iu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592380067656,"user_tz":-540,"elapsed":869,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["def train(model, device, train_loader, optimizer, criterion, logger, class_array):\n","    model.train()\n","    class_array = torch.LongTensor(class_array).to(device)\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        reg = torch.zeros(output.shape[0], 10).to(device)\n","        # reg[class_array] = output\n","        reg.index_add_(1, class_array, output)\n","        loss = criterion(reg, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            logger.debug(\"[train] batch : %s/%s (%.0f%%),\\tloss : %.6f\",\n","                batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item())\n","    return (None, loss.item())"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy3VxoCY74me","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592374871239,"user_tz":-540,"elapsed":955,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["def test(model, device, test_loader, criterion, logger, class_array):\n","    model.eval()\n","    test_loss = []\n","    correct = 0\n","    # result = []\n","    class_array = torch.tensor(class_array).to(device)\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss.append(criterion(output, target).item())\n","            pred = class_array[output.argmax(dim=1, keepdim=True)]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            # result += torch.eq(torch.max(output, 1).indices, target) # not apply\n","            \n","    test_loss = np.mean(np.array(test_loss))\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","    \n","    logger.info(\"[test] ave loss : %.4f,\\taccu : %d/%d(%.0f%%)\",\n","        test_loss, correct, len(test_loader.dataset), accuracy)\n","    \n","    # return (torch.tensor(result).numpy(), (test_loss, accuracy))\n","    return (None, (test_loss, accuracy))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ft0I0uKFEvFF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592407147851,"user_tz":-540,"elapsed":1030,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["def main(description, option=\"\"):\n","    with open('logging.json') as f:\n","        dictConfig(json.load(f))\n","    logger = getLogger('env')\n","    logger.debug(\"<\" * 40)\n","    logger.info(\"[system] start\")\n","    logger.info(\"[meta] %s\", description)\n","    start_time = time.time()\n","\n","    def fetch_args(args=[]):\n","        parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","        parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n","                            help='input batch size for training (default: 64)')\n","        parser.add_argument('--epochs', type=int, default=14, metavar='N',\n","                            help='number of epochs to train (default: 14)')\n","        parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n","                            help='learning rate (default: 0.001)')\n","        parser.add_argument('--b1', type=float, default=0.9, metavar='B',\n","                            help='learning rate beta (default: 0.9)')\n","        parser.add_argument('--b2', type=float, default=0.999, metavar='B',\n","                            help='learning rate beta (default: 0.999)')\n","        parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n","                            help='learning rate momentum (default: 0.9)')\n","        parser.add_argument('--dataset', default=\"cifar10\", metavar='D')\n","        parser.add_argument('--n-class', type=int, default=10, metavar='C')\n","        parser.add_argument('--n-class-offset', type=int, default=0, metavar='C')\n","        parser.add_argument('--data-size', type=int, default=25000, metavar='D')\n","        parser.add_argument('--model', default=\"cnn\", metavar='M')\n","        parser.add_argument('--optimizer', default=\"adam\", metavar='O')\n","        parser.add_argument('--criterion', default=\"cross_entropy_loss\", metavar='C')\n","        parser.add_argument('--scheduler', default=\"\", metavar='S')\n","        parser.add_argument('--t-max', type=int, default=10, metavar='T')\n","        parser.add_argument('--save-model', action='store_true', default=True,\n","                            help='For Saving the current Model')\n","        parser.add_argument('--model-name', default=\"model\", metavar='M')\n","        return parser.parse_args(args=args)\n","  \n","    args = fetch_args(option.split(\" \"))\n","    for arg in vars(args):\n","        logger.info(\"[param] %s=%s\", arg, vars(args)[arg])\n","    \n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    logger.info(\"[device] %s\", device)\n","    \n","    #画像の変形処理\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    #CIFAR-10のtrain, testsetのロード\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    \n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","\n","    def subset_dataloader(set):\n","      return torch.utils.data.DataLoader(\n","          torch.utils.data.Subset(trainset, set), \n","          batch_size=args.batch_size, shuffle=False, **kwargs)\n","\n","    # init\n","    def make_dataset(n_class, data_size):\n","      full_labels = []\n","      full_indices = np.arange(len(trainset))\n","      for (_, target) in subset_dataloader(full_indices):\n","        full_labels += target.numpy().tolist()\n","      full_labels = np.array(full_labels)\n","\n","      indices = np.array([], dtype=np.int64)\n","      class_sample = int(data_size / len(n_class))\n","      for c in n_class:\n","        mask = full_labels == c\n","        indices = np.concatenate([indices, full_indices[mask][:class_sample]])\n","\n","      np.random.shuffle(indices)\n","      return (indices, None, full_labels)\n","\n","    N = int(args.data_size)\n","    class_array = [(i + args.n_class_offset) % 10 for i in range(args.n_class)]\n","    class_array = np.array(class_array)\n","    print(class_array)\n","    indices, _, labels = make_dataset(class_array, 2 * N)\n","    A, B = indices[:N], indices[N:]\n","    logger.debug(\"[debug] labels : %s\", labels.tolist())\n","\n","    log = {\"X_train\":[], \"X_test\":[], \"X_acc\":[]}\n","\n","\n","    def learning():\n","      # instantiate\n","      if True:\n","        model_X = CNN(n_class=args.n_class).to(device)\n","\n","        if args.optimizer == \"adam\":\n","          optimizer_X = optim.Adam(model_X.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n","        if args.optimizer == \"adagrad\":\n","          optimizer_X = optim.Adagrad(model_X.parameters(), lr=args.lr)\n","        if args.optimizer == \"sdg\":\n","          optimizer_X = optim.SGD(model_X.parameters(), lr=args.lr, momentum=args.momentum)\n","        if args.optimizer == \"asdg\":\n","          optimizer_X = optim.ASGD(model_X.parameters(), lr=args.lr)\n","\n","        scheduler_X = None\n","        if args.scheduler == \"cosine_annealing\":\n","          scheduler_X = optim.lr_scheduler.CosineAnnealingLR(optimizer_X, T_max=args.t_max, eta_min=1e-6)\n","        if args.scheduler == \"step\":\n","          def func(epoch):\n","            return 0.5 ** (epoch // 50)\n","          scheduler_X = optim.lr_scheduler.LambdaLR(optimizer_X, lr_lambda = func)\n","        criterion = nn.CrossEntropyLoss()\n","\n","      # Split\n","      A_loader, B_loader = subset_dataloader(A), subset_dataloader(B)\n","      \n","      def fit_X():\n","        logger.info(\"[system] X\")\n","        for epoch in range(args.epochs):\n","          logger.debug(\"-\" * 20)\n","          logger.info(\"[system] epoch %d\", epoch)\n","\n","          (_, loss_XA) = train(model_X, device, A_loader, optimizer_X, criterion, logger, class_array)\n","          (testB, (loss_XB, acc_X)) = test(model_X, device, B_loader, criterion, logger, class_array)\n","          if scheduler_X: scheduler_X.step()\n","        \n","          log[\"X_train\"].append(loss_XA)\n","          log[\"X_test\"].append(loss_XB)\n","          log[\"X_acc\"].append(acc_X)\n","        return testB\n","\n","      # training\n","      testB = fit_X()\n","\n","      # save\n","      if args.save_model:\n","        logger.info(\"[system] saving...\")\n","        result_dir = \"result\"\n","        result_path = os.path.join(result_dir, args.model_name + \".pt\")\n","        if not os.path.exists(result_dir):\n","          os.mkdir(result_dir)\n","\n","        torch.save(model_X.state_dict(), result_path)\n","        # print(os.path.join(\"/content\", result_path))\n","        # files.download(os.path.join(\"/content\", result_path))\n","\n","\n","    learning()\n","\n","    # Statistics\n","    logger.debug(\"%s statistics %s\", \"-\" * 10, \"-\" * 10)\n","    logger.info(\"[stat] X train loss : %s\", log[\"X_train\"])\n","    logger.info(\"[stat] X test loss : %s\", log[\"X_test\"])\n","    logger.info(\"[stat] X accuracy : %s\", log[\"X_acc\"])\n","    logger.info(\"[stat] elapsed time : %s[s]\", time.time() - start_time)\n","    \n","    logger.info(\"[system] finish\")\n"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMRx-KNomQsX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592404247399,"user_tz":-540,"elapsed":928,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["def main(description, option=\"\"):\n","    with open('logging.json') as f:\n","        dictConfig(json.load(f))\n","    logger = getLogger('env')\n","    logger.debug(\"<\" * 40)\n","    logger.info(\"[system] start\")\n","    logger.info(\"[meta] %s\", description)\n","    start_time = time.time()\n","\n","    def fetch_args(args=[]):\n","        parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","        parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n","                            help='input batch size for training (default: 64)')\n","        parser.add_argument('--epochs', type=int, default=14, metavar='N',\n","                            help='number of epochs to train (default: 14)')\n","        parser.add_argument('--trials', type=int, default=10, metavar='T')\n","        parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n","                            help='learning rate (default: 0.001)')\n","        parser.add_argument('--b1', type=float, default=0.9, metavar='B',\n","                            help='learning rate beta (default: 0.9)')\n","        parser.add_argument('--b2', type=float, default=0.999, metavar='B',\n","                            help='learning rate beta (default: 0.999)')\n","        parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n","                            help='learning rate momentum (default: 0.9)')\n","        parser.add_argument('--dataset', default=\"cifar10\", metavar='D')\n","        parser.add_argument('--n-class', type=int, default=10, metavar='C')\n","        parser.add_argument('--n-class-offset', type=int, default=0, metavar='C')\n","        parser.add_argument('--data-size', type=int, default=25000, metavar='D')\n","        parser.add_argument('--model', default=\"cnn\", metavar='M')\n","        parser.add_argument('--optimizer', default=\"adam\", metavar='O')\n","        parser.add_argument('--criterion', default=\"cross_entropy_loss\", metavar='C')\n","        parser.add_argument('--scheduler', default=\"\", metavar='S')\n","        parser.add_argument('--t-max', type=int, default=10, metavar='T')\n","        parser.add_argument('--save-model', action='store_true', default=True,\n","                            help='For Saving the current Model')\n","        parser.add_argument('--model-name', default=\"model\", metavar='M')\n","        return parser.parse_args(args=args)\n","  \n","    args = fetch_args(option.split(\" \"))\n","    for arg in vars(args):\n","        logger.info(\"[param] %s=%s\", arg, vars(args)[arg])\n","    \n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    logger.info(\"[device] %s\", device)\n","    \n","    #画像の変形処理\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    #CIFAR-10のtrain, testsetのロード\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    \n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","\n","    def subset_dataloader(set):\n","      return torch.utils.data.DataLoader(\n","          torch.utils.data.Subset(trainset, set), \n","          batch_size=args.batch_size, **kwargs)\n","\n","    # init\n","    def make_dataset(n_class, data_size):\n","      full_labels = []\n","      full_indices = np.arange(len(trainset))\n","      for (_, target) in subset_dataloader(full_indices):\n","        full_labels += target.numpy().tolist()\n","\n","      pack = np.array([(i, full_labels[i]) for i in range(len(full_labels))\n","              if full_labels[i] in n_class])\n","      np.random.shuffle(pack)\n","      pack = pack[:data_size].tolist()\n","\n","      indices = [i for (i, _) in pack]\n","      labels = [label for (_, label) in pack]\n","      return (np.array(indices), np.array(labels), np.array(full_labels))\n","\n","    N = int(args.data_size)\n","    class_array = np.arange(args.n_class) + args.n_class_offset\n","    print(class_array)\n","    indices, _, labels = make_dataset(class_array, 2 * N)\n","    A, B = indices[:N], indices[N:]\n","    # A = indices\n","    logger.debug(\"[debug] labels : %s\", labels.tolist())\n","\n","    log = {\"X_train\":[], \"X_test\":[], \"X_acc\":[]}\n","\n","\n","    def learning():\n","      # instantiate\n","      if True:\n","        n_class = 7\n","\n","        models = []\n","        paths = [\"/content/result/model_7A_64.pt\",\n","                 \"/content/result/model_7B_64.pt\",\n","                 \"/content/result/model_7C_64.pt\"]\n","\n","        for idx, path in enumerate(paths):\n","          x = CNN(n_class=n_class).to(device)\n","          x.load_state_dict(torch.load(path))\n","          x.eval()\n","          xc = [(i + n_class * idx) % args.n_class for i in range(n_class)]\n","          models.append((xc, x))\n","\n","        model_X = catCNN(models, device).to(device)\n","\n","        criterion = nn.CrossEntropyLoss()\n","\n","      # Split\n","      A_loader, B_loader = subset_dataloader(A), subset_dataloader(B)\n","      \n","      def fit_X():\n","        logger.info(\"[system] X\")\n","        for epoch in range(args.epochs):\n","          logger.debug(\"-\" * 20)\n","          logger.info(\"[system] epoch %d\", epoch)\n","\n","          # (_, loss_XA) = train(model_X, device, A_loader, optimizer_X, criterion, logger)\n","          (testB, (loss_XB, acc_X)) = test(model_X, device, B_loader, criterion, logger, class_array)\n","          # if scheduler_X: scheduler_X.step() # うごいてなさそう\n","        \n","          # log[\"X_train\"].append(loss_XA)\n","          log[\"X_test\"].append(loss_XB)\n","          log[\"X_acc\"].append(acc_X)\n","        return testB\n","\n","      # training\n","      testB = fit_X()\n","\n","      # save\n","      if args.save_model:\n","        logger.info(\"[system] saving...\")\n","        result_dir = \"result\"\n","        result_path = os.path.join(result_dir, args.model_name + \".pt\")\n","        if not os.path.exists(result_dir):\n","          os.mkdir(result_dir)\n","\n","        torch.save(model_X.state_dict(), result_path)\n","        # print(os.path.join(\"/content\", result_path))\n","        # files.download(os.path.join(\"/content\", result_path))\n","\n","\n","    learning()\n","\n","    # Statistics\n","    logger.debug(\"%s statistics %s\", \"-\" * 10, \"-\" * 10)\n","    logger.info(\"[stat] X train loss : %s\", log[\"X_train\"])\n","    logger.info(\"[stat] X test loss : %s\", log[\"X_test\"])\n","    logger.info(\"[stat] X accuracy : %s\", log[\"X_acc\"])\n","    logger.info(\"[stat] elapsed time : %s[s]\", time.time() - start_time)\n","    \n","    logger.info(\"[system] finish\")\n"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYpONRnfEBYm","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  option = \"--epochs 3 --batch-size 16 --optimizer sdg --data-size 100 \" + \\\n","           \"--n-class 5 --n-class-offset 5 --model-name=model_0to4\"\n","  main(\"デバッグ\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8--o9wvY4xh","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  # option = \"--epochs 200 --batch-size 16 --optimizer sdg --data-size 20000 \" + \\\n","  #          \"--n-class 5 --n-class-offset 0 --model-name=model_0to4\"\n","  # main(\"5 class A\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 16 --optimizer sdg --data-size 2000 \" + \\\n","           \"--n-class 5 --n-class-offset 5 --model-name=model_5to9\"\n","  main(\"5 class B\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0CFNBvzBf2o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1592404280376,"user_tz":-540,"elapsed":27280,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}},"outputId":"23e8d448-0bb4-4cd0-c319-730e9418e206"},"source":["if __name__ == '__main__':\n","  option = \"--epochs 1 --batch-size 16 --optimizer sdg --data-size 2000 \" + \\\n","           \"--n-class 10 --n-class-offset 0 --model-name=model_10\"\n","  main(\"10 class concat\", option=option)"],"execution_count":75,"outputs":[{"output_type":"stream","text":["[system] start\n","[meta] 10 class concat\n","[param] batch_size=16\n","[param] epochs=1\n","[param] trials=10\n","[param] lr=0.001\n","[param] b1=0.9\n","[param] b2=0.999\n","[param] momentum=0.9\n","[param] dataset=cifar10\n","[param] n_class=10\n","[param] n_class_offset=0\n","[param] data_size=2000\n","[param] model=cnn\n","[param] optimizer=sdg\n","[param] criterion=cross_entropy_loss\n","[param] scheduler=\n","[param] t_max=10\n","[param] save_model=True\n","[param] model_name=model_10\n","[device] cuda\n"],"name":"stderr"},{"output_type":"stream","text":["Files already downloaded and verified\n","[0 1 2 3 4 5 6 7 8 9]\n"],"name":"stdout"},{"output_type":"stream","text":["[system] X\n","[system] epoch 0\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","[test] ave loss : 1.6154,\taccu : 1733/2000(87%)\n","[system] saving...\n","[stat] X train loss : []\n","[stat] X test loss : [1.6153689317703248]\n","[stat] X accuracy : [86.65]\n","[stat] elapsed time : 26.543549299240112[s]\n","[system] finish\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QkICfS6IIr-q","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 0 --model-name=model_7A_64\"\n","  main(\"7 class A\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 7 --model-name=model_7B_64\"\n","  main(\"7 class B\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 14 --model-name=model_7C_64\"\n","  main(\"7 class C\", option=option)\n","\n","  download_log()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_L2aWHOss4x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1592409635537,"user_tz":-540,"elapsed":2473448,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}},"outputId":"42312cf4-c153-45ec-8e83-a025636aaead"},"source":["if __name__ == '__main__':\n","  # option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 5 --n-class-offset 0 --model-name=model_5A_64\"\n","  # main(\"5 class A\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 5 --n-class-offset 5 --model-name=model_5B_64\"\n","  main(\"5 class B\", option=option)\n","\n","  download_log()"],"execution_count":79,"outputs":[{"output_type":"stream","text":["[system] start\n","[meta] 5 class B\n","[param] batch_size=64\n","[param] epochs=100\n","[param] lr=0.001\n","[param] b1=0.9\n","[param] b2=0.999\n","[param] momentum=0.9\n","[param] dataset=cifar10\n","[param] n_class=5\n","[param] n_class_offset=5\n","[param] data_size=16000\n","[param] model=cnn\n","[param] optimizer=sdg\n","[param] criterion=cross_entropy_loss\n","[param] scheduler=\n","[param] t_max=10\n","[param] save_model=True\n","[param] model_name=model_5B_64\n","[device] cuda\n"],"name":"stderr"},{"output_type":"stream","text":["Files already downloaded and verified\n","[5 6 7 8 9]\n"],"name":"stdout"},{"output_type":"stream","text":["[system] X\n","[system] epoch 0\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","[test] ave loss : 1.4502,\taccu : 1759/9000(20%)\n","[system] epoch 1\n","[test] ave loss : 1.5800,\taccu : 3019/9000(34%)\n","[system] epoch 2\n","[test] ave loss : 1.5922,\taccu : 3133/9000(35%)\n","[system] epoch 3\n","[test] ave loss : 1.6375,\taccu : 2780/9000(31%)\n","[system] epoch 4\n","[test] ave loss : 1.6498,\taccu : 2660/9000(30%)\n","[system] epoch 5\n","[test] ave loss : 1.4192,\taccu : 3193/9000(35%)\n","[system] epoch 6\n","[test] ave loss : 1.6470,\taccu : 3740/9000(42%)\n","[system] epoch 7\n","[test] ave loss : 1.5250,\taccu : 4985/9000(55%)\n","[system] epoch 8\n","[test] ave loss : 1.6491,\taccu : 6191/9000(69%)\n","[system] epoch 9\n","[test] ave loss : 1.5318,\taccu : 6253/9000(69%)\n","[system] epoch 10\n","[test] ave loss : 1.6588,\taccu : 6048/9000(67%)\n","[system] epoch 11\n","[test] ave loss : 1.5379,\taccu : 5769/9000(64%)\n","[system] epoch 12\n","[test] ave loss : 1.6537,\taccu : 7217/9000(80%)\n","[system] epoch 13\n","[test] ave loss : 1.4255,\taccu : 7204/9000(80%)\n","[system] epoch 14\n","[test] ave loss : 1.6556,\taccu : 7085/9000(79%)\n","[system] epoch 15\n","[test] ave loss : 1.4046,\taccu : 7289/9000(81%)\n","[system] epoch 16\n","[test] ave loss : 1.6566,\taccu : 7120/9000(79%)\n","[system] epoch 17\n","[test] ave loss : 1.4251,\taccu : 6299/9000(70%)\n","[system] epoch 18\n","[test] ave loss : 1.6531,\taccu : 7161/9000(80%)\n","[system] epoch 19\n","[test] ave loss : 1.4460,\taccu : 7257/9000(81%)\n","[system] epoch 20\n","[test] ave loss : 1.6546,\taccu : 7675/9000(85%)\n","[system] epoch 21\n","[test] ave loss : 1.4080,\taccu : 7352/9000(82%)\n","[system] epoch 22\n","[test] ave loss : 1.6577,\taccu : 7572/9000(84%)\n","[system] epoch 23\n","[test] ave loss : 1.5055,\taccu : 7648/9000(85%)\n","[system] epoch 24\n","[test] ave loss : 1.6629,\taccu : 7695/9000(86%)\n","[system] epoch 25\n","[test] ave loss : 1.4807,\taccu : 7686/9000(85%)\n","[system] epoch 26\n","[test] ave loss : 1.6615,\taccu : 7703/9000(86%)\n","[system] epoch 27\n","[test] ave loss : 1.4888,\taccu : 7598/9000(84%)\n","[system] epoch 28\n","[test] ave loss : 1.6592,\taccu : 7502/9000(83%)\n","[system] epoch 29\n","[test] ave loss : 1.4741,\taccu : 7822/9000(87%)\n","[system] epoch 30\n","[test] ave loss : 1.6630,\taccu : 7852/9000(87%)\n","[system] epoch 31\n","[test] ave loss : 1.3428,\taccu : 7867/9000(87%)\n","[system] epoch 32\n","[test] ave loss : 1.6619,\taccu : 7860/9000(87%)\n","[system] epoch 33\n","[test] ave loss : 1.4123,\taccu : 7915/9000(88%)\n","[system] epoch 34\n","[test] ave loss : 1.6641,\taccu : 7868/9000(87%)\n","[system] epoch 35\n","[test] ave loss : 1.3025,\taccu : 7946/9000(88%)\n","[system] epoch 36\n","[test] ave loss : 1.6641,\taccu : 7917/9000(88%)\n","[system] epoch 37\n","[test] ave loss : 0.7146,\taccu : 7739/9000(86%)\n","[system] epoch 38\n","[test] ave loss : 1.6663,\taccu : 7919/9000(88%)\n","[system] epoch 39\n","[test] ave loss : 1.3503,\taccu : 7686/9000(85%)\n","[system] epoch 40\n","[test] ave loss : 1.6647,\taccu : 8025/9000(89%)\n","[system] epoch 41\n","[test] ave loss : 0.9503,\taccu : 7941/9000(88%)\n","[system] epoch 42\n","[test] ave loss : 1.6633,\taccu : 8045/9000(89%)\n","[system] epoch 43\n","[test] ave loss : 1.4681,\taccu : 7954/9000(88%)\n","[system] epoch 44\n","[test] ave loss : 1.6620,\taccu : 7987/9000(89%)\n","[system] epoch 45\n","[test] ave loss : 1.4651,\taccu : 8103/9000(90%)\n","[system] epoch 46\n","[test] ave loss : 1.6627,\taccu : 8077/9000(90%)\n","[system] epoch 47\n","[test] ave loss : 1.0375,\taccu : 8138/9000(90%)\n","[system] epoch 48\n","[test] ave loss : 1.6631,\taccu : 8144/9000(90%)\n","[system] epoch 49\n","[test] ave loss : 1.3999,\taccu : 8085/9000(90%)\n","[system] epoch 50\n","[test] ave loss : 1.6620,\taccu : 8065/9000(90%)\n","[system] epoch 51\n","[test] ave loss : 1.4313,\taccu : 8081/9000(90%)\n","[system] epoch 52\n","[test] ave loss : 1.6635,\taccu : 8126/9000(90%)\n","[system] epoch 53\n","[test] ave loss : 1.4741,\taccu : 8183/9000(91%)\n","[system] epoch 54\n","[test] ave loss : 1.6619,\taccu : 8142/9000(90%)\n","[system] epoch 55\n","[test] ave loss : 1.4568,\taccu : 8195/9000(91%)\n","[system] epoch 56\n","[test] ave loss : 1.6633,\taccu : 8208/9000(91%)\n","[system] epoch 57\n","[test] ave loss : 1.3866,\taccu : 8193/9000(91%)\n","[system] epoch 58\n","[test] ave loss : 1.6607,\taccu : 8206/9000(91%)\n","[system] epoch 59\n","[test] ave loss : 1.4535,\taccu : 8118/9000(90%)\n","[system] epoch 60\n","[test] ave loss : 1.6621,\taccu : 8104/9000(90%)\n","[system] epoch 61\n","[test] ave loss : 1.4373,\taccu : 8026/9000(89%)\n","[system] epoch 62\n","[test] ave loss : 1.6636,\taccu : 8169/9000(91%)\n","[system] epoch 63\n","[test] ave loss : 1.4483,\taccu : 8153/9000(91%)\n","[system] epoch 64\n","[test] ave loss : 1.6637,\taccu : 8093/9000(90%)\n","[system] epoch 65\n","[test] ave loss : 1.4501,\taccu : 8238/9000(92%)\n","[system] epoch 66\n","[test] ave loss : 1.6655,\taccu : 8170/9000(91%)\n","[system] epoch 67\n","[test] ave loss : 1.5104,\taccu : 8170/9000(91%)\n","[system] epoch 68\n","[test] ave loss : 1.6609,\taccu : 8258/9000(92%)\n","[system] epoch 69\n","[test] ave loss : 1.4493,\taccu : 8190/9000(91%)\n","[system] epoch 70\n","[test] ave loss : 1.6578,\taccu : 8244/9000(92%)\n","[system] epoch 71\n","[test] ave loss : 1.5256,\taccu : 8221/9000(91%)\n","[system] epoch 72\n","[test] ave loss : 1.6555,\taccu : 8164/9000(91%)\n","[system] epoch 73\n","[test] ave loss : 1.4545,\taccu : 8286/9000(92%)\n","[system] epoch 74\n","[test] ave loss : 1.6619,\taccu : 8253/9000(92%)\n","[system] epoch 75\n","[test] ave loss : 1.4598,\taccu : 8210/9000(91%)\n","[system] epoch 76\n","[test] ave loss : 1.6656,\taccu : 8221/9000(91%)\n","[system] epoch 77\n","[test] ave loss : 1.3617,\taccu : 8245/9000(92%)\n","[system] epoch 78\n","[test] ave loss : 1.6638,\taccu : 8233/9000(91%)\n","[system] epoch 79\n","[test] ave loss : 1.3064,\taccu : 8251/9000(92%)\n","[system] epoch 80\n","[test] ave loss : 1.6595,\taccu : 8282/9000(92%)\n","[system] epoch 81\n","[test] ave loss : 0.9543,\taccu : 8232/9000(91%)\n","[system] epoch 82\n","[test] ave loss : 1.6607,\taccu : 8240/9000(92%)\n","[system] epoch 83\n","[test] ave loss : 1.4055,\taccu : 8236/9000(92%)\n","[system] epoch 84\n","[test] ave loss : 1.6549,\taccu : 8228/9000(91%)\n","[system] epoch 85\n","[test] ave loss : 1.3805,\taccu : 8293/9000(92%)\n","[system] epoch 86\n","[test] ave loss : 1.6621,\taccu : 8221/9000(91%)\n","[system] epoch 87\n","[test] ave loss : 1.3896,\taccu : 8220/9000(91%)\n","[system] epoch 88\n","[test] ave loss : 1.6616,\taccu : 8251/9000(92%)\n","[system] epoch 89\n","[test] ave loss : 1.4760,\taccu : 8289/9000(92%)\n","[system] epoch 90\n","[test] ave loss : 1.6632,\taccu : 8135/9000(90%)\n","[system] epoch 91\n","[test] ave loss : 1.4288,\taccu : 8289/9000(92%)\n","[system] epoch 92\n","[test] ave loss : 1.6637,\taccu : 8234/9000(91%)\n","[system] epoch 93\n","[test] ave loss : 1.4452,\taccu : 8307/9000(92%)\n","[system] epoch 94\n","[test] ave loss : 1.6636,\taccu : 8258/9000(92%)\n","[system] epoch 95\n","[test] ave loss : 1.3311,\taccu : 8303/9000(92%)\n","[system] epoch 96\n","[test] ave loss : 1.6642,\taccu : 8302/9000(92%)\n","[system] epoch 97\n","[test] ave loss : 1.3435,\taccu : 8303/9000(92%)\n","[system] epoch 98\n","[test] ave loss : 1.6653,\taccu : 8319/9000(92%)\n","[system] epoch 99\n","[test] ave loss : 1.4961,\taccu : 8242/9000(92%)\n","[system] saving...\n","[stat] X train loss : [2.2077248096466064, 2.198868751525879, 2.156816005706787, 2.1105945110321045, 2.0827906131744385, 1.999552607536316, 1.945055365562439, 1.838110089302063, 1.7745035886764526, 1.7230974435806274, 1.6719905138015747, 1.6588000059127808, 1.6521016359329224, 1.656120777130127, 1.6284425258636475, 1.6609396934509277, 1.6524078845977783, 1.6318483352661133, 1.6315404176712036, 1.614612102508545, 1.6334611177444458, 1.6218644380569458, 1.6090480089187622, 1.600103497505188, 1.6031402349472046, 1.616564393043518, 1.5915191173553467, 1.5645829439163208, 1.612807035446167, 1.5773248672485352, 1.609977126121521, 1.5648611783981323, 1.5839334726333618, 1.6186658143997192, 1.5504213571548462, 1.6030138731002808, 1.5590693950653076, 1.542867660522461, 1.5625852346420288, 1.5727698802947998, 1.555557131767273, 1.5612447261810303, 1.537447214126587, 1.543888807296753, 1.5420821905136108, 1.5665637254714966, 1.5479470491409302, 1.5642133951187134, 1.5075514316558838, 1.5633103847503662, 1.5596321821212769, 1.5223212242126465, 1.5125623941421509, 1.5421465635299683, 1.5346453189849854, 1.5025733709335327, 1.4963595867156982, 1.5219529867172241, 1.5048409700393677, 1.5206326246261597, 1.5246244668960571, 1.5273165702819824, 1.5228450298309326, 1.539894461631775, 1.522831678390503, 1.5119670629501343, 1.5213853120803833, 1.4939184188842773, 1.476863145828247, 1.509225845336914, 1.5380783081054688, 1.5196022987365723, 1.5323792695999146, 1.4872702360153198, 1.5068442821502686, 1.5030477046966553, 1.479993224143982, 1.4918174743652344, 1.4775046110153198, 1.510826826095581, 1.4913681745529175, 1.5052140951156616, 1.490365743637085, 1.4798085689544678, 1.5233713388442993, 1.4969639778137207, 1.48185396194458, 1.4799399375915527, 1.515692114830017, 1.4931702613830566, 1.4921425580978394, 1.4931039810180664, 1.4669084548950195, 1.4724717140197754, 1.4863700866699219, 1.483832836151123, 1.4815603494644165, 1.4613144397735596, 1.4834020137786865, 1.4809383153915405]\n","[stat] X test loss : [1.4502104571525087, 1.580047828085879, 1.5922085215859378, 1.63746373957776, 1.6498410465024043, 1.4191758987751413, 1.6470374477670549, 1.5250000564764576, 1.6491278460685244, 1.5317989587783813, 1.658814789555597, 1.5378808780764857, 1.6537272841372388, 1.4254607655477862, 1.6555866941492607, 1.404610850286822, 1.6565921699747126, 1.4251391701664484, 1.653112401353552, 1.4460303326870532, 1.6545806899138376, 1.4080274278390492, 1.6576782972254651, 1.5055172096752951, 1.6628781891038231, 1.480704107183091, 1.6615375390289524, 1.4887757157603054, 1.6592056506068995, 1.4741132124095944, 1.6629513138574912, 1.34279905566087, 1.6618693796455437, 1.4123050236532875, 1.6640763950686084, 1.3025291557853103, 1.6641448347281056, 0.7145554199286387, 1.6662753228600145, 1.3503002317239208, 1.6646803710477571, 0.9503285588947594, 1.6632582896144679, 1.4681162267711991, 1.6620136651586979, 1.465130554023364, 1.662690686841383, 1.0374740218439846, 1.6630519501706387, 1.399934080898339, 1.6620059444549236, 1.4313435343140406, 1.663453332075836, 1.4740547296848703, 1.661906344670776, 1.4567650421291378, 1.6633304619620033, 1.3866084315252643, 1.6606652956482366, 1.4534716132684802, 1.6620774463558874, 1.4372744881514963, 1.6636342452772965, 1.448290044534291, 1.663729951736775, 1.4501437574413651, 1.6654946499682488, 1.5103604734366667, 1.6609163174392483, 1.4493182580521766, 1.6577515187838399, 1.525565764582749, 1.6555026101727857, 1.4544655156473743, 1.6619395140215014, 1.4597827339848728, 1.6655585174019456, 1.3616891389197492, 1.6638354299761724, 1.3064060879091846, 1.6595276467343594, 0.9543427034472742, 1.6607197945845042, 1.4054602308476225, 1.6548999285867028, 1.380537952514405, 1.6620783805847168, 1.3895898660024006, 1.6616400543679581, 1.4760376696890973, 1.663196860898471, 1.4287772880378344, 1.6636778352953863, 1.4451914945392743, 1.6636061313304495, 1.331100623658363, 1.6642468305344278, 1.3435188751694158, 1.6652995043612542, 1.4960908450133412]\n","[stat] X accuracy : [19.544444444444444, 33.544444444444444, 34.81111111111111, 30.88888888888889, 29.555555555555557, 35.477777777777774, 41.55555555555556, 55.388888888888886, 68.78888888888889, 69.47777777777777, 67.2, 64.1, 80.18888888888888, 80.04444444444445, 78.72222222222223, 80.9888888888889, 79.11111111111111, 69.9888888888889, 79.56666666666666, 80.63333333333334, 85.27777777777777, 81.68888888888888, 84.13333333333334, 84.97777777777777, 85.5, 85.4, 85.58888888888889, 84.42222222222222, 83.35555555555555, 86.91111111111111, 87.24444444444444, 87.41111111111111, 87.33333333333333, 87.94444444444444, 87.42222222222222, 88.28888888888889, 87.96666666666667, 85.9888888888889, 87.9888888888889, 85.4, 89.16666666666667, 88.23333333333333, 89.38888888888889, 88.37777777777778, 88.74444444444444, 90.03333333333333, 89.74444444444444, 90.42222222222222, 90.4888888888889, 89.83333333333333, 89.61111111111111, 89.78888888888889, 90.28888888888889, 90.92222222222222, 90.46666666666667, 91.05555555555556, 91.2, 91.03333333333333, 91.17777777777778, 90.2, 90.04444444444445, 89.17777777777778, 90.76666666666667, 90.58888888888889, 89.92222222222222, 91.53333333333333, 90.77777777777777, 90.77777777777777, 91.75555555555556, 91.0, 91.6, 91.34444444444445, 90.71111111111111, 92.06666666666666, 91.7, 91.22222222222223, 91.34444444444445, 91.61111111111111, 91.47777777777777, 91.67777777777778, 92.02222222222223, 91.46666666666667, 91.55555555555556, 91.5111111111111, 91.42222222222222, 92.14444444444445, 91.34444444444445, 91.33333333333333, 91.67777777777778, 92.1, 90.38888888888889, 92.1, 91.4888888888889, 92.3, 91.75555555555556, 92.25555555555556, 92.24444444444444, 92.25555555555556, 92.43333333333334, 91.57777777777778]\n","[stat] elapsed time : 2467.407196044922[s]\n","[system] finish\n"],"name":"stderr"},{"output_type":"stream","text":["/content/log.txt\n"],"name":"stdout"},{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-59bda6f77fc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5 class B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mdownload_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-72-180865867cac>\u001b[0m in \u001b[0;36mdownload_log\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"log.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   })\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"]}]},{"cell_type":"code","metadata":{"id":"-Nqk3qVlRk3W","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  # option = \"--epochs 100 --batch-size 128 --optimizer sdg --data-size 4000 \" + \\\n","  #          \"--lr 0.01 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\"\n","  # main(\"7 class debug\", option=option) # 65%\n","\n","  # option = \"--epochs 300 --batch-size 512 --optimizer sdg --data-size 2000 \" + \\\n","  #          \"--lr 0.1 --scheduler step \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 52%\n","  # main(\"7 class debug\", option=option)\n","\n","  # option = \"--epochs 100 --batch-size 32 --optimizer sdg --data-size 8000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 75%, 30min\n","  # main(\"7 class debug\", option=option)\n","  \n","  # option = \"--epochs 150 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 80%, 50min\n","  # main(\"7 class debug\", option=option)\n","\n","  # option = \"--epochs 150 --batch-size 16 --optimizer sdg --data-size 4000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 68%, 30min\n","  # main(\"7 class debug\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPNsrhFWH2C5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592394832306,"user_tz":-540,"elapsed":942,"user":{"displayName":"Stand Rights","photoUrl":"","userId":"00208011058625639860"}}},"source":["def download_log():\n","  result_path = \"log.txt\"\n","  print(os.path.join(\"/content\", result_path))\n","  files.download(os.path.join(\"/content\", result_path))"],"execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"PV5pwc4qH3ab","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}